{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uas-dtu/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/utils/generic.py:484: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/uas-dtu/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/utils/generic.py:341: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/uas-dtu/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/utils/generic.py:341: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2025-02-18 13:03:50.838833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739864030.860623  476708 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739864030.867221  476708 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 13:03:50.891408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/uas-dtu/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/utils/generic.py:341: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "REFERENCE_DATE = datetime(1970, 1, 1)\n",
    "\n",
    "def process_timestamp(timestamp):\n",
    "   \n",
    "    date_part = timestamp[:8]  \n",
    "    time_part = timestamp[8:] \n",
    "\n",
    "    date_obj = datetime.strptime(date_part, \"%Y%m%d\")\n",
    "    days_since_epoch = (date_obj - REFERENCE_DATE).days\n",
    "\n",
    "    return days_since_epoch, int(time_part)\n",
    "\n",
    "def replace_x_with_127(ip_address):\n",
    "   \n",
    "    if ip_address.endswith(\".*\"):\n",
    "        return ip_address[:-2] + \".127\"\n",
    "    return ip_address\n",
    "\n",
    "def ip_to_numeric(ip_address):\n",
    "    \"\"\"\n",
    "    Convert an IP address (e.g., '192.168.1.1') to a 32-bit integer.\n",
    "    If the IP address is invalid or missing, return a default value (e.g., 127).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        ip_address = replace_x_with_127(ip_address)\n",
    "        octets = list(map(int, ip_address.split(\".\")))\n",
    "        numeric_ip = (octets[0] << 24) + (octets[1] << 16) + (octets[2] << 8) + octets[3]\n",
    "        return numeric_ip\n",
    "    except (IndexError, ValueError, AttributeError):\n",
    "        return 127\n",
    "\n",
    "profile_json_path = f\"../profile.json\"\n",
    "with open(profile_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    profile_embeddings = json.load(f)\n",
    "\n",
    "advertiser_json_path = f\"../avertiser_id.json\"\n",
    "with open(advertiser_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    advertiser_embeddings = json.load(f)\n",
    "    \n",
    "INTERESTS = [\n",
    "    \"10006\", \"10024\", \"10031\", \"10048\", \"10052\", \"10057\", \"10059\", \"10063\", \"10067\", \"10074\",\n",
    "    \"10075\", \"10076\", \"10077\", \"10079\", \"10083\", \"10093\", \"10102\", \"10684\", \"11092\", \"11278\",\n",
    "    \"11379\", \"11423\", \"11512\", \"11576\", \"11632\", \"11680\", \"11724\", \"11944\", \"13042\", \"13403\",\n",
    "    \"13496\", \"13678\", \"13776\", \"13800\", \"13866\", \"13874\", \"14273\", \"16593\", \"16617\", \"16661\",\n",
    "    \"16706\", \"16751\", \"10110\", \"10111\"\n",
    "]\n",
    "\n",
    "def get_interest_scores(profile_interests, advertiser_id):\n",
    "    interest_vector = np.zeros(44)  \n",
    "    advertiser_data = advertiser_embeddings.get(str(advertiser_id), {})\n",
    "    advertiser_embedding = np.array(advertiser_data.get(\"embed\", [0] * 512))\n",
    "    n_value = float(advertiser_data.get(\"N\", 0))\n",
    "    for i, interest_id in enumerate(INTERESTS):\n",
    "        if interest_id in profile_interests:\n",
    "            profile_embedding = np.array(profile_embeddings.get(interest_id, {}).get(\"embed\", [0] * 512))\n",
    "            similarity = cosine_similarity([advertiser_embedding], [profile_embedding])[0][0]\n",
    "            interest_vector[i] = similarity*n_value \n",
    "    return interest_vector\n",
    "\n",
    "class RTBDataset_new(Dataset):\n",
    "    def __init__(self, imp_file_path, clk_file_path, city_embeddings_path, region_embeddings_path):\n",
    "        super().__init__()\n",
    "        with open(city_embeddings_path, 'r') as f:\n",
    "            self.city_embeddings_dict = json.load(f)\n",
    "\n",
    "        with open(region_embeddings_path, 'r') as f:\n",
    "            self.region_embeddings_dict = json.load(f)\n",
    "        \n",
    "        self.column_names = [\n",
    "        \"BidID\", \"Timestamp\", \"Logtype\", \"VisitorID\", \"User-Agent\", \"IP\", \"Region\", \"City\",\n",
    "        \"Adexchange\", \"Domain\", \"URL\", \"AnonymousURLID\", \"AdslotID\", \"Adslotwidth\",\n",
    "        \"Adslotheight\", \"Adslotvisibility\", \"Adslotformat\", \"Adslotfloorprice\",\n",
    "        \"CreativeID\", \"Biddingprice\", \"Payingprice\", \"KeypageURL\", \"AdvertiserID\", \"User_tag\"\n",
    "        ]\n",
    "        \n",
    "        self.imp = pd.read_csv(imp_file_path, delimiter='\\t',names=self.column_names ,low_memory=True)\n",
    "        self.clk = pd.read_csv(clk_file_path, delimiter='\\t',names=self.column_names ,low_memory=True)\n",
    "        \n",
    "        self.should_bid = self.imp['BidID'].isin(self.clk['BidID'])\n",
    "        self.paying_price = self.imp['Payingprice']\n",
    "        \n",
    "        self.imp['IP_numeric'] = self.imp['IP'].apply(ip_to_numeric)\n",
    "        min_value = self.imp['IP_numeric'].min()\n",
    "        max_value = self.imp['IP_numeric'].max()\n",
    "        self.imp['IP_numeric_normalized'] = (self.imp['IP_numeric'] - min_value) / (max_value - min_value)\n",
    "        self.imp[['days_since_epoch', 'time_part']] = self.imp['Timestamp'].apply(\n",
    "            lambda x: pd.Series(process_timestamp(str(x)))\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imp)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.imp.iloc[idx]\n",
    "        should_bid = float(self.should_bid.iloc[idx])\n",
    "        paying_price = float(self.paying_price.iloc[idx]) if not pd.isna(self.paying_price.iloc[idx]) else 0.0\n",
    "        advertiser_id = row['AdvertiserID']\n",
    "        profile_interests = row['User_tag']\n",
    "        if not pd.isna(profile_interests):\n",
    "            interest_scores = get_interest_scores(profile_interests, advertiser_id)\n",
    "        else:\n",
    "            interest_scores=torch.zeros(44)\n",
    "            \n",
    "        city_embedding = self.city_embeddings_dict.get(str(row['City']), self.city_embeddings_dict[\"0\"])\n",
    "        region_embedding = self.region_embeddings_dict.get(str(row['Region']), self.region_embeddings_dict[\"0\"])\n",
    "        ad_features = np.array([\n",
    "            int(row['Adslotwidth']), int(row['Adslotheight']),\n",
    "            int(row['Adslotvisibility']), int(row['Adslotformat']),\n",
    "            float(row['Adslotfloorprice']),row['days_since_epoch'], row['time_part'], row['IP_numeric_normalized']\n",
    "        ])\n",
    "  \n",
    "       \n",
    "        features = np.concatenate([\n",
    "            ad_features,\n",
    "            city_embedding,\n",
    "            region_embedding,\n",
    "            interest_scores\n",
    "        ])\n",
    "        return features , should_bid, paying_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intialising dataset.....\n",
      "initalisation complete!\n",
      "[768, 192, 48, 12, 3]\n",
      "[3, 12, 48, 192, 768]\n",
      "[44, 32, 16]\n",
      "[16, 32, 44]\n",
      "[28, 64, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imp_file = \"../../../../ignore/Adobe Devcraft Dataset/dataset/clk.12.txt\"\n",
    "clk_file = \"../../../../ignore/Adobe Devcraft Dataset/dataset/clk.12.txt\"\n",
    "city_file = r\"city_embeddings.json\"\n",
    "region_file = r\"region_embeddings.json\"\n",
    "# from train_xgboost_real import RTBDataset_new\n",
    "print('intialising dataset.....')\n",
    "dataset = RTBDataset_new(imp_file, clk_file, city_file,region_file)\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "print('initalisation complete!')\n",
    "\n",
    "all_features = []\n",
    "all_should_bid = []\n",
    "all_paying_price = []\n",
    "\n",
    "from model import BidPredictor\n",
    "model_weights='model_paramsRepresentative/epoch16_iter_220_train_44.93674087524414'\n",
    "model=BidPredictor(768).to('cuda')\n",
    "model.load_state_dict(torch.load(model_weights),strict=False)\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "        # print(\"in loop\")\n",
    "        # ad_features,city,interest, should_bid, paying_price = batch\n",
    "        features, should_bid, paying_price = batch\n",
    "        all_features.append(features)\n",
    "        # all_features.append(model(ad_features.to('cuda').float(),city.to('cuda').float(),interest.to('cuda').float()).detach().cpu().numpy( ))\n",
    "        all_should_bid.append(should_bid)\n",
    "        all_paying_price.append(paying_price)\n",
    "\n",
    "X = np.vstack(all_features)\n",
    "y_bid = np.hstack(all_should_bid)\n",
    "y_price = np.hstack(all_paying_price)\n",
    "\n",
    "# X_train, X_test, y_bid_train, y_bid_test, y_price_train, y_price_test = train_test_split(\n",
    "#     X, y_bid, y_price, test_size=0.05, random_state=42\n",
    "# )\n",
    "# print(X.shape,y_price.shape,y_bid_train.shape)\n",
    "\n",
    "# scale_pos_weight = (y_bid_train == 0).sum() / (y_bid_train == 1).sum()\n",
    "\n",
    "xgb_params_bid = {\n",
    "    \"n_estimators\": 100, \n",
    "    \"max_depth\": 5,       \n",
    "    \"learning_rate\": 0.1,  \n",
    "    \"objective\": \"binary:logistic\", \n",
    "    \"eval_metric\": \"logloss\",  \n",
    "    \"use_label_encoder\": False,\n",
    "    \"subsample\": 0.8,    \n",
    "    \"colsample_bytree\": 0.8, \n",
    "    \"reg_alpha\": 0.1,    \n",
    "    \"reg_lambda\": 0.1,    \n",
    "    \"seed\": 42,\n",
    "    # \"scale_pos_weight\": scale_pos_weight           \n",
    "}\n",
    "\n",
    "quantile_alpha = 0.1\n",
    "\n",
    "xgb_params_price = {\n",
    "    \"n_estimators\": 100,  \n",
    "    \"max_depth\": 5,      \n",
    "    \"learning_rate\": 0.1, \n",
    "    \"objective\": \"reg:quantileerror\",  \n",
    "    \"quantile_alpha\": quantile_alpha, \n",
    "    \"eval_metric\": \"rmse\", \n",
    "    \"subsample\": 0.8,    \n",
    "    \"colsample_bytree\": 0.8, \n",
    "    \"reg_alpha\": 0.1,     \n",
    "    \"reg_lambda\": 0.1,    \n",
    "    \"seed\": 42            \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8307\n",
      "Precision: 1.0000\n",
      "Recall: 0.8307\n",
      "F1 Score: 0.9075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uas-dtu/anaconda3/envs/llava/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_bid = joblib.load(\"xgb_bid_model_old.joblib\")\n",
    "\n",
    "# Predict the labels\n",
    "y_bid_pred = model_bid.predict(X)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_bid, y_bid_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute Precision\n",
    "precision = precision_score(y_bid, y_bid_pred, average='weighted')  # Use 'binary' for binary classification\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Compute Recall\n",
    "recall = recall_score(y_bid, y_bid_pred, average='weighted')\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(y_bid, y_bid_pred, average='weighted')\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Compute ROC-AUC Score (Only for binary or multilabel classification)\n",
    "if len(np.unique(y_bid)) == 2:\n",
    "    roc_auc = roc_auc_score(y_bid, model_bid.predict_proba(X)[:, 1])  # Probability for the positive class\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_bid, model_bid.predict_proba(X)[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for reference\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0]\n",
      " [ 272 1335]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  confusion_matrix\n",
    "import seaborn as sns\n",
    "matrix=confusion_matrix(y_bid, y_bid_pred)\n",
    "print(matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xgb_price_mode_old.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_price \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgb_price_mode_old.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_pred_price \u001b[38;5;241m=\u001b[39m model_price\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Compute Mean Squared Error (MSE)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xgb_price_mode_old.joblib'"
     ]
    }
   ],
   "source": [
    "model_price = joblib.load(\"xgb_price_mode_old.joblib\")\n",
    "\n",
    "y_pred_price = model_price.predict(X)\n",
    "\n",
    "# Compute Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_true=y_price, y_pred=y_pred_price)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "# Compute R-squared (R2) score\n",
    "r2 = r2_score(y_true=y_price, y_pred=y_pred_price)\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
