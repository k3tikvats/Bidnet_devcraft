2025-02-10 02:11:38 - INFO - ------------------------------------------------------------------------------------------------
2025-02-10 02:11:38 - INFO - starting new training !!!!
2025-02-10 02:11:38 - INFO - ------------------------------------------------------------------------------------------------
2025-02-10 02:11:38 - INFO - Namespace(lr=0.0001, batch=32, epoch=50, data_dir='', save_dir='model_parameter', weight_fac=1, save_freq=2, log_dir='logs', gamma=0.1, step_size=2, model_path=None, log_interval=100, embed_dim=768)
2025-02-10 02:11:38 - INFO - parameters are being saved at :model_parameter/4
2025-02-10 02:11:38 - INFO - BidPredictor(
  (Region_compressor): Sequential(
    (0): Sequential(
      (0): Linear(in_features=768, out_features=192, bias=True)
      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (1): Sequential(
      (0): Linear(in_features=192, out_features=48, bias=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (2): Sequential(
      (0): Linear(in_features=48, out_features=12, bias=True)
      (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (3): Sequential(
      (0): Linear(in_features=12, out_features=3, bias=True)
      (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
  )
  (City_compressor): Sequential(
    (0): Sequential(
      (0): Linear(in_features=768, out_features=192, bias=True)
      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (1): Sequential(
      (0): Linear(in_features=192, out_features=48, bias=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (2): Sequential(
      (0): Linear(in_features=48, out_features=12, bias=True)
      (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (3): Sequential(
      (0): Linear(in_features=12, out_features=3, bias=True)
      (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
  )
  (alignment): Sequential(
    (0): Sequential(
      (0): Linear(in_features=44, out_features=8, bias=True)
      (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (1): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Linear(in_features=18, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (1): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (2): Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (3): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
    (4): Sequential(
      (0): Linear(in_features=256, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
    )
  )
  (classifier): Linear(in_features=512, out_features=2, bias=True)
  (sigmoid): Sigmoid()
)
2025-02-10 02:16:45 - INFO - epoch:0/50 iteration:0/4 batch loss is :160.8363
2025-02-10 02:16:46 - INFO - Epoch:0/50 Loss is :139.8573
2025-02-10 02:16:46 - INFO - average cls loss is :0.5955
2025-02-10 02:16:46 - INFO - average q divergence is : 139.2619
2025-02-10 02:16:46 - INFO - VAL loss :149.0548
2025-02-10 02:16:47 - INFO - epoch:1/50 iteration:0/4 batch loss is :156.1206
2025-02-10 02:16:47 - INFO - Epoch:1/50 Loss is :139.7882
2025-02-10 02:16:47 - INFO - average cls loss is :0.5586
2025-02-10 02:16:47 - INFO - average q divergence is : 139.2296
2025-02-10 02:16:47 - INFO - epoch:2/50 iteration:0/4 batch loss is :175.7782
2025-02-10 02:16:48 - INFO - Epoch:2/50 Loss is :139.7446
2025-02-10 02:16:48 - INFO - average cls loss is :0.5405
2025-02-10 02:16:48 - INFO - average q divergence is : 139.2041
2025-02-10 02:16:48 - INFO - VAL loss :148.9993
2025-02-10 02:16:48 - INFO - epoch:3/50 iteration:0/4 batch loss is :200.1330
2025-02-10 02:16:48 - INFO - Epoch:3/50 Loss is :139.7402
2025-02-10 02:16:48 - INFO - average cls loss is :0.5387
2025-02-10 02:16:48 - INFO - average q divergence is : 139.2015
2025-02-10 02:16:48 - INFO - epoch:4/50 iteration:0/4 batch loss is :211.3471
2025-02-10 02:16:49 - INFO - Epoch:4/50 Loss is :139.7240
2025-02-10 02:16:49 - INFO - average cls loss is :0.5361
2025-02-10 02:16:49 - INFO - average q divergence is : 139.1879
2025-02-10 02:16:49 - INFO - VAL loss :148.9917
2025-02-10 02:16:49 - INFO - epoch:5/50 iteration:0/4 batch loss is :189.5402
2025-02-10 02:16:49 - INFO - Epoch:5/50 Loss is :139.7434
2025-02-10 02:16:49 - INFO - average cls loss is :0.5422
2025-02-10 02:16:49 - INFO - average q divergence is : 139.2012
2025-02-10 02:16:49 - INFO - epoch:6/50 iteration:0/4 batch loss is :199.9701
2025-02-10 02:16:49 - INFO - Epoch:6/50 Loss is :139.7226
2025-02-10 02:16:49 - INFO - average cls loss is :0.5383
2025-02-10 02:16:50 - INFO - average q divergence is : 139.1843
2025-02-10 02:16:50 - INFO - VAL loss :148.9912
2025-02-10 02:16:50 - INFO - epoch:7/50 iteration:0/4 batch loss is :154.8281
2025-02-10 02:16:50 - INFO - Epoch:7/50 Loss is :139.7405
2025-02-10 02:16:50 - INFO - average cls loss is :0.5374
2025-02-10 02:16:50 - INFO - average q divergence is : 139.2032
2025-02-10 02:16:50 - INFO - epoch:8/50 iteration:0/4 batch loss is :176.1839
2025-02-10 02:16:51 - INFO - Epoch:8/50 Loss is :139.7228
2025-02-10 02:16:51 - INFO - average cls loss is :0.5355
2025-02-10 02:16:51 - INFO - average q divergence is : 139.1873
2025-02-10 02:16:51 - INFO - VAL loss :148.9928
2025-02-10 02:16:51 - INFO - epoch:9/50 iteration:0/4 batch loss is :146.1908
2025-02-10 02:16:51 - INFO - Epoch:9/50 Loss is :139.7323
2025-02-10 02:16:51 - INFO - average cls loss is :0.5372
2025-02-10 02:16:51 - INFO - average q divergence is : 139.1951
2025-02-10 02:16:51 - INFO - epoch:10/50 iteration:0/4 batch loss is :163.8082
2025-02-10 02:16:51 - INFO - Epoch:10/50 Loss is :139.7280
2025-02-10 02:16:51 - INFO - average cls loss is :0.5369
2025-02-10 02:16:51 - INFO - average q divergence is : 139.1912
2025-02-10 02:16:51 - INFO - VAL loss :148.9958
2025-02-10 02:16:52 - INFO - epoch:11/50 iteration:0/4 batch loss is :174.8480
2025-02-10 02:16:52 - INFO - Epoch:11/50 Loss is :139.7261
2025-02-10 02:16:52 - INFO - average cls loss is :0.5354
2025-02-10 02:16:52 - INFO - average q divergence is : 139.1908
2025-02-10 02:16:52 - INFO - epoch:12/50 iteration:0/4 batch loss is :156.5654
2025-02-10 02:16:52 - INFO - Epoch:12/50 Loss is :139.7326
2025-02-10 02:16:52 - INFO - average cls loss is :0.5379
2025-02-10 02:16:52 - INFO - average q divergence is : 139.1946
2025-02-10 02:16:52 - INFO - VAL loss :148.9942
2025-02-10 02:16:53 - INFO - epoch:13/50 iteration:0/4 batch loss is :154.2261
2025-02-10 02:16:53 - INFO - Epoch:13/50 Loss is :139.7271
2025-02-10 02:16:53 - INFO - average cls loss is :0.5362
2025-02-10 02:16:53 - INFO - average q divergence is : 139.1910
2025-02-10 02:16:53 - INFO - epoch:14/50 iteration:0/4 batch loss is :172.5955
2025-02-10 02:16:53 - INFO - Epoch:14/50 Loss is :139.7209
2025-02-10 02:16:53 - INFO - average cls loss is :0.5354
2025-02-10 02:16:53 - INFO - average q divergence is : 139.1855
2025-02-10 02:16:53 - INFO - VAL loss :148.9910
2025-02-10 02:16:53 - INFO - epoch:15/50 iteration:0/4 batch loss is :195.9880
2025-02-10 02:16:54 - INFO - Epoch:15/50 Loss is :139.7249
2025-02-10 02:16:54 - INFO - average cls loss is :0.5363
2025-02-10 02:16:54 - INFO - average q divergence is : 139.1886
2025-02-10 02:16:54 - INFO - epoch:16/50 iteration:0/4 batch loss is :168.6136
2025-02-10 02:16:54 - INFO - Epoch:16/50 Loss is :139.7297
2025-02-10 02:16:54 - INFO - average cls loss is :0.5368
2025-02-10 02:16:54 - INFO - average q divergence is : 139.1929
2025-02-10 02:16:54 - INFO - VAL loss :148.9932
2025-02-10 02:16:54 - INFO - epoch:17/50 iteration:0/4 batch loss is :183.6825
2025-02-10 02:16:55 - INFO - Epoch:17/50 Loss is :139.7263
2025-02-10 02:16:55 - INFO - average cls loss is :0.5360
2025-02-10 02:16:55 - INFO - average q divergence is : 139.1903
2025-02-10 02:16:55 - INFO - epoch:18/50 iteration:0/4 batch loss is :170.2608
2025-02-10 02:16:55 - INFO - Epoch:18/50 Loss is :139.7258
2025-02-10 02:16:55 - INFO - average cls loss is :0.5352
2025-02-10 02:16:55 - INFO - average q divergence is : 139.1905
2025-02-10 02:16:55 - INFO - VAL loss :148.9929
2025-02-10 02:16:55 - INFO - epoch:19/50 iteration:0/4 batch loss is :171.3264
2025-02-10 02:16:56 - INFO - Epoch:19/50 Loss is :139.7267
2025-02-10 02:16:56 - INFO - average cls loss is :0.5374
2025-02-10 02:16:56 - INFO - average q divergence is : 139.1894
2025-02-10 02:16:56 - INFO - epoch:20/50 iteration:0/4 batch loss is :163.4574
2025-02-10 02:16:56 - INFO - Epoch:20/50 Loss is :139.7345
2025-02-10 02:16:56 - INFO - average cls loss is :0.5393
2025-02-10 02:16:56 - INFO - average q divergence is : 139.1953
2025-02-10 02:16:56 - INFO - VAL loss :148.9908
2025-02-10 02:16:56 - INFO - epoch:21/50 iteration:0/4 batch loss is :192.8980
2025-02-10 02:16:57 - INFO - Epoch:21/50 Loss is :139.7232
2025-02-10 02:16:57 - INFO - average cls loss is :0.5357
2025-02-10 02:16:57 - INFO - average q divergence is : 139.1875
2025-02-10 02:16:57 - INFO - epoch:22/50 iteration:0/4 batch loss is :143.3524
2025-02-10 02:16:57 - INFO - Epoch:22/50 Loss is :139.7302
2025-02-10 02:16:57 - INFO - average cls loss is :0.5360
2025-02-10 02:16:57 - INFO - average q divergence is : 139.1942
2025-02-10 02:16:57 - INFO - VAL loss :148.9902
2025-02-10 02:16:57 - INFO - epoch:23/50 iteration:0/4 batch loss is :185.6583
2025-02-10 02:16:58 - INFO - Epoch:23/50 Loss is :139.7366
2025-02-10 02:16:58 - INFO - average cls loss is :0.5389
2025-02-10 02:16:58 - INFO - average q divergence is : 139.1977
2025-02-10 02:16:58 - INFO - epoch:24/50 iteration:0/4 batch loss is :200.7139
2025-02-10 02:16:58 - INFO - Epoch:24/50 Loss is :139.7247
2025-02-10 02:16:58 - INFO - average cls loss is :0.5345
2025-02-10 02:16:58 - INFO - average q divergence is : 139.1902
2025-02-10 02:16:58 - INFO - VAL loss :148.9952
2025-02-10 02:16:58 - INFO - epoch:25/50 iteration:0/4 batch loss is :225.9907
2025-02-10 02:16:59 - INFO - Epoch:25/50 Loss is :139.7317
2025-02-10 02:16:59 - INFO - average cls loss is :0.5375
2025-02-10 02:16:59 - INFO - average q divergence is : 139.1941
2025-02-10 02:16:59 - INFO - epoch:26/50 iteration:0/4 batch loss is :186.6190
2025-02-10 02:16:59 - INFO - Epoch:26/50 Loss is :139.7348
2025-02-10 02:16:59 - INFO - average cls loss is :0.5367
2025-02-10 02:16:59 - INFO - average q divergence is : 139.1981
2025-02-10 02:16:59 - INFO - VAL loss :148.9915
2025-02-10 02:16:59 - INFO - epoch:27/50 iteration:0/4 batch loss is :150.7880
2025-02-10 02:17:00 - INFO - Epoch:27/50 Loss is :139.7419
2025-02-10 02:17:00 - INFO - average cls loss is :0.5380
2025-02-10 02:17:00 - INFO - average q divergence is : 139.2040
2025-02-10 02:17:00 - INFO - epoch:28/50 iteration:0/4 batch loss is :175.9658
2025-02-10 02:17:00 - INFO - Epoch:28/50 Loss is :139.7263
2025-02-10 02:17:00 - INFO - average cls loss is :0.5376
2025-02-10 02:17:00 - INFO - average q divergence is : 139.1887
2025-02-10 02:17:00 - INFO - VAL loss :148.9960
2025-02-10 02:17:00 - INFO - epoch:29/50 iteration:0/4 batch loss is :173.0398
2025-02-10 02:17:01 - INFO - Epoch:29/50 Loss is :139.7348
2025-02-10 02:17:01 - INFO - average cls loss is :0.5340
2025-02-10 02:17:01 - INFO - average q divergence is : 139.2008
2025-02-10 02:17:01 - INFO - epoch:30/50 iteration:0/4 batch loss is :147.3852
2025-02-10 02:17:01 - INFO - Epoch:30/50 Loss is :139.7268
2025-02-10 02:17:01 - INFO - average cls loss is :0.5359
2025-02-10 02:17:01 - INFO - average q divergence is : 139.1909
2025-02-10 02:17:01 - INFO - VAL loss :148.9883
2025-02-10 02:17:01 - INFO - epoch:31/50 iteration:0/4 batch loss is :182.1970
2025-02-10 02:17:01 - INFO - Epoch:31/50 Loss is :139.7386
2025-02-10 02:17:01 - INFO - average cls loss is :0.5355
2025-02-10 02:17:01 - INFO - average q divergence is : 139.2031
2025-02-10 02:17:01 - INFO - epoch:32/50 iteration:0/4 batch loss is :184.4515
2025-02-10 02:17:02 - INFO - Epoch:32/50 Loss is :139.7260
2025-02-10 02:17:02 - INFO - average cls loss is :0.5363
2025-02-10 02:17:02 - INFO - average q divergence is : 139.1897
2025-02-10 02:17:02 - INFO - VAL loss :148.9883
2025-02-10 02:17:02 - INFO - epoch:33/50 iteration:0/4 batch loss is :154.8288
2025-02-10 02:17:02 - INFO - Epoch:33/50 Loss is :139.7260
2025-02-10 02:17:02 - INFO - average cls loss is :0.5353
2025-02-10 02:17:02 - INFO - average q divergence is : 139.1907
2025-02-10 02:17:02 - INFO - epoch:34/50 iteration:0/4 batch loss is :166.0812
2025-02-10 02:17:03 - INFO - Epoch:34/50 Loss is :139.7321
2025-02-10 02:17:03 - INFO - average cls loss is :0.5391
2025-02-10 02:17:03 - INFO - average q divergence is : 139.1930
2025-02-10 02:17:03 - INFO - VAL loss :148.9963
2025-02-10 02:17:03 - INFO - epoch:35/50 iteration:0/4 batch loss is :160.6449
2025-02-10 02:17:03 - INFO - Epoch:35/50 Loss is :139.7258
2025-02-10 02:17:03 - INFO - average cls loss is :0.5355
2025-02-10 02:17:03 - INFO - average q divergence is : 139.1903
2025-02-10 02:17:03 - INFO - epoch:36/50 iteration:0/4 batch loss is :134.6447
2025-02-10 02:17:04 - INFO - Epoch:36/50 Loss is :139.7325
2025-02-10 02:17:04 - INFO - average cls loss is :0.5369
2025-02-10 02:17:04 - INFO - average q divergence is : 139.1956
2025-02-10 02:17:04 - INFO - VAL loss :148.9922
2025-02-10 02:17:04 - INFO - epoch:37/50 iteration:0/4 batch loss is :170.3521
2025-02-10 02:17:04 - INFO - Epoch:37/50 Loss is :139.7214
2025-02-10 02:17:04 - INFO - average cls loss is :0.5373
2025-02-10 02:17:04 - INFO - average q divergence is : 139.1841
2025-02-10 02:17:04 - INFO - epoch:38/50 iteration:0/4 batch loss is :188.8550
2025-02-10 02:17:05 - INFO - Epoch:38/50 Loss is :139.7255
2025-02-10 02:17:05 - INFO - average cls loss is :0.5351
2025-02-10 02:17:05 - INFO - average q divergence is : 139.1905
2025-02-10 02:17:05 - INFO - VAL loss :148.9934
2025-02-10 02:17:05 - INFO - epoch:39/50 iteration:0/4 batch loss is :164.5001
2025-02-10 02:17:06 - INFO - Epoch:39/50 Loss is :139.7275
2025-02-10 02:17:06 - INFO - average cls loss is :0.5368
2025-02-10 02:17:06 - INFO - average q divergence is : 139.1907
2025-02-10 02:17:06 - INFO - epoch:40/50 iteration:0/4 batch loss is :149.6600
2025-02-10 02:17:06 - INFO - Epoch:40/50 Loss is :139.7332
2025-02-10 02:17:06 - INFO - average cls loss is :0.5360
2025-02-10 02:17:06 - INFO - average q divergence is : 139.1971
2025-02-10 02:17:06 - INFO - VAL loss :148.9900
2025-02-10 02:17:06 - INFO - epoch:41/50 iteration:0/4 batch loss is :182.2567
2025-02-10 02:17:06 - INFO - Epoch:41/50 Loss is :139.7180
2025-02-10 02:17:06 - INFO - average cls loss is :0.5348
2025-02-10 02:17:06 - INFO - average q divergence is : 139.1832
2025-02-10 02:17:06 - INFO - epoch:42/50 iteration:0/4 batch loss is :180.4050
2025-02-10 02:17:07 - INFO - Epoch:42/50 Loss is :139.7226
2025-02-10 02:17:07 - INFO - average cls loss is :0.5353
2025-02-10 02:17:07 - INFO - average q divergence is : 139.1874
2025-02-10 02:17:07 - INFO - VAL loss :148.9918
2025-02-10 02:17:07 - INFO - epoch:43/50 iteration:0/4 batch loss is :154.1321
2025-02-10 02:17:07 - INFO - Epoch:43/50 Loss is :139.7242
2025-02-10 02:17:07 - INFO - average cls loss is :0.5351
2025-02-10 02:17:07 - INFO - average q divergence is : 139.1892
2025-02-10 02:17:07 - INFO - epoch:44/50 iteration:0/4 batch loss is :185.1313
2025-02-10 02:17:07 - INFO - Epoch:44/50 Loss is :139.7303
2025-02-10 02:17:07 - INFO - average cls loss is :0.5369
2025-02-10 02:17:07 - INFO - average q divergence is : 139.1934
2025-02-10 02:17:08 - INFO - VAL loss :148.9946
2025-02-10 02:17:08 - INFO - epoch:45/50 iteration:0/4 batch loss is :155.1860
2025-02-10 02:17:08 - INFO - Epoch:45/50 Loss is :139.7289
2025-02-10 02:17:08 - INFO - average cls loss is :0.5357
2025-02-10 02:17:08 - INFO - average q divergence is : 139.1931
2025-02-10 02:17:08 - INFO - epoch:46/50 iteration:0/4 batch loss is :179.2045
2025-02-10 02:17:08 - INFO - Epoch:46/50 Loss is :139.7363
2025-02-10 02:17:08 - INFO - average cls loss is :0.5409
2025-02-10 02:17:08 - INFO - average q divergence is : 139.1954
2025-02-10 02:17:08 - INFO - VAL loss :148.9946
2025-02-10 02:17:09 - INFO - epoch:47/50 iteration:0/4 batch loss is :162.0153
2025-02-10 02:17:09 - INFO - Epoch:47/50 Loss is :139.7259
2025-02-10 02:17:09 - INFO - average cls loss is :0.5369
2025-02-10 02:17:09 - INFO - average q divergence is : 139.1890
2025-02-10 02:17:09 - INFO - epoch:48/50 iteration:0/4 batch loss is :205.0749
2025-02-10 02:17:09 - INFO - Epoch:48/50 Loss is :139.7373
2025-02-10 02:17:09 - INFO - average cls loss is :0.5374
2025-02-10 02:17:09 - INFO - average q divergence is : 139.1999
2025-02-10 02:17:09 - INFO - VAL loss :148.9913
2025-02-10 02:17:10 - INFO - epoch:49/50 iteration:0/4 batch loss is :189.0190
2025-02-10 02:17:10 - INFO - Epoch:49/50 Loss is :139.7323
2025-02-10 02:17:10 - INFO - average cls loss is :0.5367
2025-02-10 02:17:10 - INFO - average q divergence is : 139.1956
2025-02-10 02:17:10 - INFO - training complete!!!
